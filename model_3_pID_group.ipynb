{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Going to open: https://gopuff.okta.com/app/snowflake/exk25gqvk9wE1DhXJ4x7/sso/saml?SAMLRequest=nZJPc9owEMW%2Fikc925IdKEUDZEgIrdOkOGCaDDfFFkaxLTlaGUM%2BfWX%2BdNJDcuhNI73d39O%2BHVzuysLZcg1CySHyPYIcLhOVCpkN0TKeut%2BQA4bJlBVK8iHac0CXowGwsqjouDYbOeevNQfj2EYSaPswRLWWVDEQQCUrOVCT0MX4%2Fo4GHqEMgGtjcehUkoKwrI0xFcW4aRqvufCUznBACMGkj62qlXxB7xDV54xKK6MSVZxLdvZPHyB8TDotwiosIToVXgl5HMFnlOejCOiPOI7caLaIkTM%2B%2F%2B5aSahLrhdcb0XCl%2FO7owGwDr7PouV06nEGxq3BDTz2VmvugVTNumA5T1RZ1ca29uwJr3mKC5UJO7BwMkRVLtK3OHx49h%2FnN6%2BPpLl42eXzqxXT0c%2BnfXcFs4x0Xu5vO7msHliYIOf3Od6gjTcEqHko21CNvSJBxyU9N%2BjHxKdBl%2FpfvR7pr5AzsaEKycyh8uw8U1W9XnsqN%2BzgjVUV%2Fmsb810edLPXbd5vbvzJ5um2s%2BthAIXbyNBxa%2BiBr0f%2FNYsBft%2FitIW%2FbDDhJFKFSPbOVOmSmY9z8z3%2FcCNSd32QUl4yUYzTVHMAm19RqOZac2bsshtdc4RHR%2Bq%2F6z76Aw%3D%3D&RelayState=64951 to authenticate...\n"
     ]
    }
   ],
   "source": [
    "from snowflake import connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ctx = connector.connect(\n",
    "        user=\"namitha.john@gopuff.com\",\n",
    "        authenticator=\"externalbrowser\",\n",
    "        role=\"READER_ROLE\",\n",
    "        warehouse=\"READER_WH\",\n",
    "        account=\"gopuff.east-us-2.azure\",\n",
    "    )\n",
    "cur = ctx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        LOCATION_ID  PRODUCT_ID  SUM(EXPIRY_RISK_QUANTITY)  \\\n",
      "0               135          25                          0   \n",
      "1                68          29                        -13   \n",
      "2               100          29                        -45   \n",
      "3               252          29                          0   \n",
      "4               257          29                          0   \n",
      "...             ...         ...                        ...   \n",
      "200225          881      225208                          0   \n",
      "200226         1025      225208                          0   \n",
      "200227           30      225210                          0   \n",
      "200228          621      225210                          0   \n",
      "200229         1025      225210                          0   \n",
      "\n",
      "       SUM(EXPIRY_RISK_COST)  MAX(RECENT_CASE_PACK)  PRODUCT_ID  LOCATION_ID  \\\n",
      "0                   0.000000                   10.0          25          135   \n",
      "1                 -13.000000                   72.0          29           68   \n",
      "2                 -45.000000                   72.0          29          100   \n",
      "3                   0.000000                   72.0          29          252   \n",
      "4                   0.000000                   72.0          29          257   \n",
      "...                      ...                    ...         ...          ...   \n",
      "200225              0.000000                   12.0      225208          881   \n",
      "200226              0.000000                   12.0      225208         1025   \n",
      "200227              0.000000                   12.0      225210           30   \n",
      "200228              0.000000                   12.0      225210          621   \n",
      "200229              0.000000                   12.0      225210         1025   \n",
      "\n",
      "       MAX(EVENT_TIME_OPS_DATE)  \n",
      "0                    2022-04-25  \n",
      "1                    2024-05-31  \n",
      "2                    2022-07-14  \n",
      "3                    2024-02-14  \n",
      "4                    2024-06-01  \n",
      "...                         ...  \n",
      "200225               2024-07-24  \n",
      "200226               2024-07-10  \n",
      "200227               2024-07-13  \n",
      "200228               2024-07-08  \n",
      "200229               2024-07-10  \n",
      "\n",
      "[200230 rows x 8 columns]\n",
      "cutoff:\n",
      "2024-05-31\n",
      "cutoff:\n",
      "2022-07-14\n",
      "cutoff:\n",
      "2024-02-14\n",
      "cutoff:\n",
      "2024-06-01\n",
      "cutoff:\n",
      "2022-07-04\n",
      "data:\n",
      "[[68, 29, -13, 72.0], [100, 29, -45, 72.0], [252, 29, 0, 72.0], [257, 29, 0, 72.0], [299, 29, -77, 72.0]]\n",
      "[68, 100, 252, 257, 299]\n",
      "[[29 13 'pack' 'packed' datetime.date(2022, 9, 26) -1]\n",
      " [29 13 'pack' 'packed' datetime.date(2022, 9, 26) -1]\n",
      " [29 13 'pack' 'packed' datetime.date(2022, 9, 26) -1]\n",
      " ...\n",
      " [29 1169 'sell' 'shelved' datetime.date(2024, 7, 17) -1]\n",
      " [29 1570 'inventory_control_count' 'discovered'\n",
      "  datetime.date(2023, 11, 7) 72]\n",
      " [29 1570 'pack' 'packed' datetime.date(2024, 3, 16) -1]]\n",
      "[68, 100, 252, 257, 299]\n",
      "first loc\n",
      "13\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "4\n",
      "after loc\n",
      "4\n",
      "data:\n",
      "[68, 29, -13, 72.0, 68, 29, 0, 12.0, 0, [], 0, []]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loc_ID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 228\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mprint\u001b[39m(data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m#call in replenishment data for product ID and location ID\u001b[39;00m\n\u001b[1;32m    226\u001b[0m SQL_repl \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124mselect RECOMMENDATION_CREATION_DATE,FINAL_RECOMMENDATION,LOCATION_ID,PRODUCT_ID,ORDER_DATE,NEED_BY_DATE, BUY_QUANTITY_EACHES from dbt_buffet.core.o9_replenishments_recommendations\u001b[39m\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;124mwhere (final_recommendation=TRUE) AND PRODUCT_ID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AND LOCATION_ID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AND ORDER_DATE >= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcutoff_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124mORDER BY ORDER_DATE\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m#SQL call for forecasting data (raw data)\u001b[39;00m\n\u001b[1;32m    232\u001b[0m SQL_fore \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124mselect LOCATION_ID, PRODUCT_ID,FORECASTED_DATE,MODEL_FORECAST,FINAL_FORECAST from dbt_prod.core.supply_plan_forecast\u001b[39m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124mwhere PRODUCT_ID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AND LOCATION_ID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloc_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AND FORECASTED_DATE >= \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcutoff_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124mORDER BY FORECASTED_DATE, DS_FORECAST_STARTED_AT DESC\u001b[39m\u001b[38;5;124m'''\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loc_ID' is not defined"
     ]
    }
   ],
   "source": [
    "#bring in all product/location intersections in expiry risk table sorted by Expiry Risk Cost in descending order\n",
    "SQL = '''\n",
    "with expiry as (select LOCATION_ID, PRODUCT_ID,SUM(EXPIRY_RISK_QUANTITY), SUM(EXPIRY_RISK_COST), MAX(RECENT_CASE_PACK) from dbt_buffet.core.inventory_expiration_risk \n",
    "WHERE NOT LOCATION_NAME='NJ_DC_1179' AND NOT LOCATION_NAME='CA_DC_1486' AND EXPIRY_RISK_COST IS NOT NULL\n",
    "GROUP BY 1,2)\n",
    "   , inventory_rec as (SELECT PRODUCT_ID, LOCATION_ID, MAX(EVENT_TIME_OPS_DATE) from   dbt_prod.core.inventory_reconciliation\n",
    "    where event_state in ('damaged', 'expired')\n",
    "    GROUP BY 1,2)\n",
    "select *\n",
    "from expiry\n",
    "        join inventory_rec\n",
    "                   on expiry.LOCATION_ID = inventory_rec.LOCATION_ID AND\n",
    "                      expiry.PRODUCT_ID = inventory_rec.PRODUCT_ID\n",
    "    ORDER BY 2,1\n",
    ";\n",
    "'''\n",
    "\n",
    "og_expiry = cur.execute(SQL).fetch_pandas_all()\n",
    "print(og_expiry)\n",
    "expiry = og_expiry.to_numpy()\n",
    "final_report = []\n",
    "all_rc = [0] * 5\n",
    "\n",
    "#cycle through every product location intersection in expiry table\n",
    "for e in range(1,2):\n",
    "    #data array will contain all information need to find root cause\n",
    "    data = []\n",
    "    cutoff_dates = []\n",
    "    locs = []\n",
    "#for e in range(2,4):\n",
    "    #loc_ID = expiry[e][0]\n",
    "    p_ID = expiry[e][1]\n",
    "    #loc_ID = 675\n",
    "    #p_ID = 651444\n",
    "    #print(e)\n",
    "    #print(p_ID)\n",
    "    while expiry[e][1] == p_ID and e < len(expiry):\n",
    "        data.append([expiry[e][0],p_ID,expiry[e][2],expiry[e][4]])        \n",
    "        cutoff_dates.append(expiry[e][7])\n",
    "        locs.append(expiry[e][0])\n",
    "        print(\"cutoff:\")\n",
    "        print(expiry[e][7])\n",
    "        e += 1\n",
    "    e =- 1\n",
    "    \n",
    "    current_loc = 0\n",
    "    current_loc_ind = -1\n",
    "\n",
    "    print(\"data:\")\n",
    "    print(data)\n",
    "    print(locs)\n",
    "    #call in inventory reconciliation table for product/location intersection\n",
    "    SQL_2 = f'''\n",
    "    with expiry as (select distinct location_id,\n",
    "                                product_id\n",
    "                from dbt_buffet.core.inventory_expiration_risk\n",
    "                where expiry_risk_cost is not null)\n",
    "   , inventory_rec as (select product_id,\n",
    "                              location_id,\n",
    "                              action,\n",
    "                              event_state,\n",
    "                              event_time_ops_date,\n",
    "                              signed_quantity\n",
    "                       from dbt_prod.core.inventory_reconciliation)\n",
    "select inventory_rec.*\n",
    "from inventory_rec\n",
    "         join expiry\n",
    "              on expiry.location_id = inventory_rec.location_id AND\n",
    "                 expiry.product_id = inventory_rec.product_id\n",
    "where true\n",
    "  and inventory_rec.location_id not in (1179, 1486)\n",
    "  and event_state in ('packed', 'discovered', 'lost', 'shelved', 'damage', 'expired')\n",
    "  and event_time_ops_date >= current_date - interval '2 years'\n",
    "  and inventory_rec.product_id = {p_ID}\n",
    "order by location_id, event_time_ops_date'''\n",
    "\n",
    "    inventory_rec = cur.execute(SQL_2).fetch_pandas_all()\n",
    "    inventory_rec = inventory_rec.to_numpy()\n",
    "    print(inventory_rec)\n",
    "\n",
    "    if len(inventory_rec) != 0:\n",
    "\n",
    "        #number of recieves in timeframe\n",
    "        num_recieves = 0\n",
    "\n",
    "        #list of weekly sell rate in timeframe\n",
    "        sell_rate = []\n",
    "\n",
    "        #variables used to track week partitioning in data\n",
    "        week_sell_rate = 0.0\n",
    "        prev_week_number = 0\n",
    "        prev_year_number = 0\n",
    "        prev_date = inventory_rec[0][4]\n",
    "\n",
    "        #six week average including current week\n",
    "        avg_sell_rate = 0.0\n",
    "\n",
    "        #total_quantity at any point of time with product (possibly not needed)\n",
    "        total_quantity = 0\n",
    "\n",
    "        #instance of vendor damage with date of occurance\n",
    "        vendor=[]\n",
    "\n",
    "        #instances of off-shelf damage with date of occurance\n",
    "        shelf = []\n",
    "    print(locs)\n",
    "\n",
    "    #cycling through all instances of inventory rec\n",
    "    for product in inventory_rec:\n",
    "        if current_loc == 0:\n",
    "            current_loc = product[1]\n",
    "            current_loc_ind = 0\n",
    "            #print(\"first loc\")\n",
    "            #print(product[1])\n",
    "            while locs[current_loc_ind] != current_loc and current_loc_ind < len(locs)-1:\n",
    "                #loc_ID,p_ID,expiry[e][2],expiry[e][4],num_recieves,sell_rate,total_quantity,vendor\n",
    "                data[current_loc_ind].extend([locs[current_loc_ind], p_ID,expiry[e][2],expiry[e][4], 0,[],0,[]])\n",
    "                current_loc_ind = current_loc_ind + 1\n",
    "\n",
    "        elif current_loc != product[1]:\n",
    "            #print(current_loc_ind)\n",
    "            data[current_loc_ind].extend([current_loc,p_ID,expiry[e][2],expiry[e][4],num_recieves,sell_rate,total_quantity,vendor])\n",
    "            current_loc = product[1]\n",
    "            #print(\"after loc\")\n",
    "            #print(current_loc_ind)\n",
    "            while current_loc_ind < len(locs)-1 and locs[current_loc_ind] != current_loc:\n",
    "                print(current_loc_ind)\n",
    "                #loc_ID,p_ID,expiry[e][2],expiry[e][4],num_recieves,sell_rate,total_quantity,vendor\n",
    "                data[current_loc_ind].extend([locs[current_loc_ind], p_ID,expiry[e][2],expiry[e][4], 0,[],0,[]])\n",
    "                current_loc_ind = current_loc_ind + 1\n",
    "            num_recieves = 0\n",
    "\n",
    "            #list of weekly sell rate in timeframe\n",
    "            sell_rate = []\n",
    "\n",
    "            #variables used to track week partitioning in data\n",
    "            week_sell_rate = 0.0\n",
    "            prev_week_number = 0\n",
    "            prev_year_number = 0\n",
    "            prev_date = inventory_rec[0][4]\n",
    "\n",
    "            #six week average including current week\n",
    "            avg_sell_rate = 0.0\n",
    "\n",
    "            #total_quantity at any point of time with product (possibly not needed)\n",
    "            total_quantity = 0\n",
    "\n",
    "            #instance of vendor damage with date of occurance\n",
    "            vendor=[]\n",
    "\n",
    "        #add signed quanitity to track total_quantity\n",
    "        total_quantity += product[5]\n",
    "        event= product[3]\n",
    "        date = product[4]\n",
    "\n",
    "        #shelved is when product is recieved \n",
    "        if  event=='shelved':\n",
    "            num_recieves = num_recieves + 1\n",
    "        \n",
    "        #packed is when product is sold\n",
    "        elif event== 'packed':\n",
    "            # d is week of date of packed event\n",
    "            d = int(date.strftime(\"%U\"))\n",
    "            #case of current event is within current week\n",
    "            if(d == prev_week_number and date.isocalendar().year == prev_year_number):\n",
    "                week_sell_rate -= product[5]\n",
    "\n",
    "            #for case of first instance of packed event\n",
    "            elif (prev_week_number == 0):\n",
    "                week_sell_rate -= product[5]\n",
    "                prev_week_number = d\n",
    "                prev_year_number = date.isocalendar().year\n",
    "                prev_date = date\n",
    "\n",
    "            #in case of different week then current tracked week\n",
    "            else:\n",
    "                i = len(sell_rate)-1\n",
    "                #calc what to divide average by in cause of less then 6 weeks looked at \n",
    "                div = 6\n",
    "\n",
    "                #calc avg sell rate\n",
    "                if i < 4:\n",
    "                    div = len(sell_rate) +1\n",
    "                    for w in sell_rate:\n",
    "                        avg_sell_rate += w[1]\n",
    "                else:\n",
    "                    for count in range(5):\n",
    "                        avg_sell_rate += sell_rate[i][1]\n",
    "                        i-= 1\n",
    "                avg_sell_rate = (avg_sell_rate + week_sell_rate)/div\n",
    "\n",
    "                #add to sell rate list [date of week, sell rate of week, avg of sell rate, current total quantity] of old current week\n",
    "                sell_rate.append([prev_date,week_sell_rate,avg_sell_rate, total_quantity])\n",
    "\n",
    "                #case of adding all weeks-- to implement\n",
    "                #sell_rate[-1][1] = week_sell_rate/7\n",
    "                #prev_week_number+= 1\n",
    "                #while prev_week_number != d:\n",
    "                    #week_date =datetime.strptime(str(prev_year_number)+ \" \" + str(prev_week_number) + ' 0', \"%Y %W %w\")\n",
    "                    #sell_rate.append((week_date,0,avg_sell_rate,total_quantity))\n",
    "                    #prev_week_number+=1\n",
    "                \n",
    "                #set up for new current week to look at\n",
    "                week_sell_rate =  0 - product[5]\n",
    "                prev_week_number=d\n",
    "                prev_year_number = date.isocalendar().year\n",
    "                prev_date=date\n",
    "\n",
    "            #if case of a damage event\n",
    "        elif event=='damaged':\n",
    "            #before 2023 and in Warehouses, product is recieved to shelf before being damaged so it should be removed from total_quantity count \n",
    "            if date.isocalendar().year < 2023 or (\"DC\" in str(product[1])):\n",
    "                total_quantity = total_quantity - product[5]\n",
    "            \n",
    "            #in case of vendor damage out\n",
    "            if \"vendor\" in product[2]:\n",
    "                vendor.append((date,product[5]))\n",
    "                #print(vendor)\n",
    "            \n",
    "    #data will have location ID, Product ID, expiry risk quantity, case pack size, num of recieves, list of weekly sell rates, total_quantity, vendor damage, off-shelf damage\n",
    "    #data.append([loc_ID,p_ID,expiry[e][2],expiry[e][4],num_recieves,sell_rate,total_quantity,vendor,shelf])\n",
    "    print(\"data:\")\n",
    "    print(data[0])\n",
    "\n",
    "    #call in replenishment data for product ID and location ID\n",
    "    SQL_repl = f'''\n",
    "    with expiry as (select distinct location_id,\n",
    "                                product_id\n",
    "                from dbt_buffet.core.inventory_expiration_risk\n",
    "                where expiry_risk_cost is not null)\n",
    "   , repl as (select RECOMMENDATION_CREATION_DATE,FINAL_RECOMMENDATION,LOCATION_ID,PRODUCT_ID,ORDER_DATE,NEED_BY_DATE, BUY_QUANTITY_EACHES from dbt_buffet.core.o9_replenishments_recommendations\n",
    "    where (final_recommendation=TRUE)\n",
    "    ORDER BY LOCATION_ID,ORDER_DATE)\n",
    "select repl.*\n",
    "from repl\n",
    "         join expiry\n",
    "              on expiry.location_id = repl.location_id AND\n",
    "                 expiry.product_id = repl.product_id\n",
    "where true\n",
    "  and repl.location_id not in (1179, 1486)\n",
    "  and order_date >= current_date - interval '2 years'\n",
    "  and repl.product_id = {p_ID}\n",
    "order by location_id, order_date'''\n",
    "\n",
    "    #SQL call for forecasting data (raw data)\n",
    "    SQL_fore = f'''\n",
    "    with expiry as (select distinct location_id,\n",
    "                                product_id\n",
    "                from dbt_buffet.core.inventory_expiration_risk\n",
    "                where expiry_risk_cost is not null)\n",
    "   , fore as (select LOCATION_ID, PRODUCT_ID,FORECASTED_DATE,MODEL_FORECAST,FINAL_FORECAST, DS_FORECAST_STARTED_AT from dbt_prod.core.supply_plan_forecast\n",
    "    ORDER BY LOCATION_ID,FORECASTED_DATE, DS_FORECAST_STARTED_AT DESC)\n",
    "select fore.*\n",
    "from fore\n",
    "         join expiry\n",
    "              on expiry.location_id = fore.location_id AND\n",
    "                 expiry.product_id = fore.product_id\n",
    "where true\n",
    "  and fore.location_id not in (1179, 1486)\n",
    "  and ds_forecast_started_at >= current_date - interval '2 years'\n",
    "  and fore.product_id = {p_ID}\n",
    "order by location_id, forecasted_date, ds_forecast_started_at DESC'''\n",
    "\n",
    "    #SQL call for purchasing data (data for purchasing orders)\n",
    "    SQL_purch = f'''\n",
    "    with expiry as (select distinct location_id,\n",
    "                                product_id\n",
    "                from dbt_buffet.core.inventory_expiration_risk\n",
    "                where expiry_risk_cost is not null)\n",
    "   , purch as (select GP_ITEM_ID, SHIP_TO_GP_LOCATION_ID, NEED_BY_DATE, LBI_QTY_RECEIVED, CLOSED_FOR_RECEIVING_AT from dbt_prod.core.purchase_order_lines\n",
    "    ORDER BY NEED_BY_DATE)\n",
    "select purch.*\n",
    "from purch\n",
    "         join expiry\n",
    "              on expiry.location_id = purch.ship_to_gp_location_id AND\n",
    "                 expiry.product_id = purch.gp_item_id\n",
    "where true\n",
    "  and purch.ship_to_gp_location_id not in (1179, 1486)\n",
    "  and need_by_date >= current_date - interval '2 years'\n",
    "  and purch.gp_item_id = {p_ID}\n",
    "order by location_id, need_by_date\n",
    "    '''\n",
    "\n",
    "    #SQL call for lbi transitions data (for expiration dates)\n",
    "    SQL_lbi = f'''with expiry as (select distinct location_id,\n",
    "                                product_id\n",
    "                from dbt_buffet.core.inventory_expiration_risk\n",
    "                where expiry_risk_cost is not null)\n",
    "   , lbi as (select PRODUCT_ID,LOCATION_ID,EVENT_TIME_OPS_DATE, ACTION, DELTA, STATE, EXPIRATION_DATE from dbt_prod.core.lbi_transitions\n",
    "    WHERE action in ('receive', 'receive_to_shelf')\n",
    "    and state in ('shelved', 'received')\n",
    "    ORDER BY LOCATION_ID, EVENT_TIME_OPS_DATE, EXPIRATION_DATE)\n",
    "select lbi.*\n",
    "from lbi\n",
    "         join expiry\n",
    "              on expiry.location_id = lbi.location_id AND\n",
    "                 expiry.product_id = lbi.product_id\n",
    "where true\n",
    "  and lbi.location_id not in (1179, 1486)\n",
    "  and event_time_ops_date >= current_date - interval '2 years'\n",
    "  and lbi.product_id = {p_ID}\n",
    "order by location_id, event_time_ops_date, expiration_date'''\n",
    "\n",
    "    replenishment = cur.execute(SQL_repl).fetch_pandas_all()\n",
    "    forecast = cur.execute(SQL_fore).fetch_pandas_all()\n",
    "    purchase_orders = cur.execute(SQL_purch).fetch_pandas_all()\n",
    "    lbi_trans = cur.execute(SQL_lbi).fetch_pandas_all()\n",
    "\n",
    "    #print(replenishment)\n",
    "    #print(forecast)\n",
    "    #print(purchase_orders)\n",
    "    #print(lbi_trans)\n",
    "\n",
    "    replenishment=replenishment.to_numpy()\n",
    "    forecast = forecast.to_numpy()\n",
    "    purchase_orders=purchase_orders.to_numpy()\n",
    "    lbi_trans = lbi_trans.to_numpy()\n",
    "\n",
    "    current_pos = 0\n",
    "    current_loc_ind = 0\n",
    "    current_loc = 0\n",
    "    sell_rates = []\n",
    "\n",
    "    #link replenishment to weekly sell rate in sell rate list\n",
    "    for i in replenishment:\n",
    "        #print(i[4])\n",
    "        if current_loc == 0:\n",
    "            current_loc = replenishment[1]\n",
    "            #print(\"first loc\")\n",
    "            #print(product[1])\n",
    "            while locs[current_loc_ind] != current_loc and current_loc_ind < len(locs)-1:\n",
    "                #loc_ID,p_ID,expiry[e][2],expiry[e][4],num_recieves,sell_rate,total_quantity,vendor\n",
    "                data[current_pos][5].append(-1)\n",
    "                current_pos = current_pos + 1\n",
    "            sell_rates = data[current_pos][5]\n",
    "\n",
    "        elif current_loc != product[1]:\n",
    "            #print(current_loc_ind)\n",
    "            data[current_loc_ind][5] = sell_rates\n",
    "            current_loc = product[1]\n",
    "            #print(\"after loc\")\n",
    "            #print(current_loc_ind)\n",
    "            while current_loc_ind < len(locs)-1 and locs[current_loc_ind] != current_loc:\n",
    "                print(current_loc_ind)\n",
    "                #loc_ID,p_ID,expiry[e][2],expiry[e][4],num_recieves,sell_rate,total_quantity,vendor\n",
    "                data[current_loc_ind][5].append(-1)\n",
    "                current_loc_ind = current_loc_ind + 1\n",
    "            sell_rates = data[current_pos][5]\n",
    "        #sell_rates = data[0][5]\n",
    "        date = i[5]\n",
    "        year = date.strftime(\"%Y\")\n",
    "        week = date.strftime(\"%U\")\n",
    "        found = False\n",
    "        #go through each sell_rate list entry to find what sell rate correlates to which replenishment entry based on week \n",
    "        while (found != True and current_pos != len(sell_rate)):\n",
    "            drate = sell_rates[current_pos][0]\n",
    "            if((drate.strftime(\"%U\")== week) and (drate.strftime(\"%Y\") == year)):\n",
    "                #if week correlates is found append value\n",
    "                sell_rates[current_pos].append(i[6])\n",
    "                found = True\n",
    "            else:\n",
    "                #if week correlates is not found, append -1\n",
    "                sell_rates[current_pos].append(-1)\n",
    "            #done this way so never go back through sell rates/optimize\n",
    "            current_pos= current_pos + 1\n",
    "\n",
    "    # for case where there is no replenishment data, all entry is -1\n",
    "    if len(replenishment) == 0:\n",
    "        for l in locs: \n",
    "            for s in data[l][5]:\n",
    "                s.append(-1)\n",
    "    else:\n",
    "        while current_pos != len(sell_rates):\n",
    "            sell_rates[current_pos].append(-1)\n",
    "            current_pos = current_pos + 1\n",
    "\n",
    "    #each entry in sell rates look like: [date, weekly_sell_rate, avg_sell_rate, total_qty, repln link ]\n",
    "    print(\"repln:\")\n",
    "    #print(len(replenishment))\n",
    "    print(sell_rates[1])\n",
    "\n",
    "    #coral will store forecasting link data\n",
    "    coral = [-1] * len(sell_rates)\n",
    "    #print(coral)\n",
    "\n",
    "    #link raw demand forecast data to weekly sell rate in sell rate list\n",
    "    for i in forecast:\n",
    "        date = i[2]\n",
    "        year = date.strftime(\"%Y\")\n",
    "        week = date.strftime(\"%U\")\n",
    "        found = False\n",
    "        #print(year) range(len(sell_rate))\n",
    "        #drate = sell_rates[current_pos][0]\n",
    "        #if((drate.strftime(\"%U\")== week) and (drate.strftime(\"%Y\") == year\n",
    "        #go through each sell rate to find correlating raw demand data-- optimization possible?\n",
    "        for s in range(len(sell_rates)):\n",
    "            drate = sell_rates[s][0]\n",
    "            if ((drate.strftime(\"%U\")==week) and (drate.strftime(\"%Y\")== year) and coral[s] == -1):\n",
    "                coral[s] = i[4]\n",
    "            # print(coral[s])\n",
    "                #print(coral)\n",
    "                #print(i[4])\n",
    "    #print(coral)\n",
    "    #once all correlation found, append to sell rates\n",
    "    for s in range(len(sell_rates)):\n",
    "       # print(coral[s])\n",
    "        sell_rates[s].append(coral[s])\n",
    "    print(\"forecast:\")\n",
    "    print(sell_rates[1])\n",
    "\n",
    "    #each entry in sell rates look like: [date, weekly_sell_rate, avg_sell_rate, total_qty, repln link, forecasting link ]\n",
    "\n",
    "    #this code is to link each week with a purchase order if it is present-- needed?\n",
    "    current_pos = 0\n",
    "    for i in purchase_orders:\n",
    "        date = i[2]\n",
    "        year = date.strftime(\"%Y\")\n",
    "        week = date.strftime(\"%U\")\n",
    "        found = False\n",
    "        #print(year) range(len(sell_rate))\n",
    "        #append purchase order quanitity if found, -1 if nothing found\n",
    "        while (found != True and current_pos < len(sell_rates)):\n",
    "            #print(current_pos)\n",
    "            drate = sell_rates[current_pos][0]\n",
    "            if((drate.strftime(\"%U\")== week) and (drate.strftime(\"%Y\") == year)):\n",
    "                sell_rates[current_pos].append(i[3])\n",
    "                #print(i[3])\n",
    "                found = True\n",
    "            else:\n",
    "                sell_rates[current_pos].append(-1)\n",
    "            current_pos= current_pos + 1\n",
    "    \n",
    "    #if no purchase orders, entire row is -1\n",
    "    if len(purchase_orders) == 0:\n",
    "        for s in sell_rates:\n",
    "            s.append(-1)\n",
    "    else:\n",
    "        #if less purchase orders then dates in sell_rate table, append -1 for remaining\n",
    "        while current_pos != len(sell_rates):\n",
    "            sell_rates[current_pos].append(-1)\n",
    "            current_pos = current_pos + 1\n",
    "    print(\"po:\")\n",
    "    print(sell_rates[1])\n",
    "\n",
    "    #each entry in sell rates look like: [date, weekly_sell_rate, avg_sell_rate, total_qty, repln link,forecasting link, purchase order link ]\n",
    "\n",
    "    #go through lbi_trans to find if week has correlating expiration date\n",
    "    #coral will store all data\n",
    "    coral = [None] * len(sell_rates)\n",
    "    for i in lbi_trans:\n",
    "        date = i[2]\n",
    "        year = date.strftime(\"%Y\")\n",
    "        week = date.strftime(\"%U\")\n",
    "        #print(year) range(len(sell_rate))\n",
    "        #current iteration will only use earliest expiration-- not all same\n",
    "        #go through to see if there is correlating expiration date-- possible optimization\n",
    "        for s in range(len(sell_rates)):\n",
    "            drate = sell_rates[s][0]\n",
    "            if ((drate.strftime(\"%U\")==week) and (drate.strftime(\"%Y\")== year) and coral[s] == None):\n",
    "                coral[s] = i[6]\n",
    "    \n",
    "    #append -1 if expiration date not found\n",
    "    for s in range(len(sell_rates)):\n",
    "        #print(coral[s])\n",
    "        if coral[s] == None:\n",
    "            sell_rates[s].append(-1)\n",
    "        else:\n",
    "            sell_rates[s].append(coral[s])\n",
    "    \n",
    "    #each entry in sell rates look like: [date, weekly_sell_rate, avg_sell_rate, total_qty, repln link,forecasting link, purchase order link, expiration date]\n",
    "\n",
    "    #identifing root cause\n",
    "\n",
    "    print(\"lbi_trans\")\n",
    "    print(sell_rates[1])\n",
    "    data[0][5] = sell_rates\n",
    "    d = data[0]\n",
    "    found = False\n",
    "    total = 0\n",
    "    root_cause = []\n",
    "    #i = len(d[5])-1\n",
    "    if len(d[5]) != 0:\n",
    "        #print(\"in if\")\n",
    "        sell_rate = d[5]\n",
    "        i = len(d[5])-1\n",
    "        i_last_expiry = 0\n",
    "        today = datetime.now()\n",
    "        #find index of  earliest sell rate with expiration date after today\n",
    "        while found != True and i > 0 and i < len(d[5]):\n",
    "            #print(d)\n",
    "            #print(\"split\")\n",
    "            #print(d[5][i])\n",
    "            #print(i)\n",
    "            if d[5][i][7] != -1:\n",
    "                #print(d[5][i][7])\n",
    "                if d[5][i][7] < today:\n",
    "                    found = True\n",
    "                    i_last_expiry = i + 1\n",
    "            i = i -1\n",
    "        if i_last_expiry > len(d[5])-1:\n",
    "           i_last_expiry = len(d[5])-1\n",
    "\n",
    "        #vendor D&E\n",
    "        vendor_bool = False\n",
    "        vi = 0\n",
    "        #if there is a vendor damage event present within weeks, vendor damage event\n",
    "        if  len(d[7]) != 0:\n",
    "            while vi < len(d[7]) and vendor_bool == False:\n",
    "            #for v in d[7]:\n",
    "                #maybe check by week instead?\n",
    "                v = d[7][vi]\n",
    "                #print(i_last_expiry)\n",
    "                #print(d[5])\n",
    "                if d[5][i_last_expiry][0] < v[0]:\n",
    "                    vendor_bool= True\n",
    "                vi = vi+1\n",
    "            if vendor_bool == True:\n",
    "                root_cause.append(\"vendor D&E\")\n",
    "                all_rc[0] = all_rc[0] + 1\n",
    "\n",
    "    #new product forecast\n",
    "    #if num_recieves is less than 4 in weeks-- New Product Forecast (might need to be rechecked)\n",
    "        if d[4] < 4:\n",
    "            #print(\"new forecast\")\n",
    "            #print(d[5])\n",
    "            avg = d[5][-1][2]\n",
    "            if avg < 5:\n",
    "                root_cause.append(\"New Product Forecast\")\n",
    "                all_rc[1] = all_rc[1] + 1\n",
    "        i = i_last_expiry\n",
    "        #both of following can have weekly breakdown\n",
    "        found_of = False\n",
    "        found_cp = False\n",
    "        #if forecasted data is more than 2x the sell rate-- overforecasting\n",
    "        while i != len(sell_rate) and found_of == False:\n",
    "            #over forecasting\n",
    "            #print(d[5][i])\n",
    "            if d[5][i][4] > ((d[5][i][1])*2):\n",
    "                #root_cause.append((d[5][i][0],\"Over Forecasting\",d[5][i][4] , d[5][i][1]*2))\n",
    "                found_of = True\n",
    "                all_rc[2] = all_rc[2] + 1\n",
    "            i = i + 1\n",
    "        i = i_last_expiry\n",
    "        #if sell_rate/raw demand is much larger and is a multiple of case pack--possible optimization\n",
    "        while i != len(sell_rate) and found_cp == False:\n",
    "            #need to fix case pack\n",
    "            if d[5][i][4] > ((d[5][i][1])*2):\n",
    "                if (((d[5][i][4]) % d[3]) == 0):\n",
    "                #root_cause.append(\"Case Pack\")\n",
    "                    found_cp = True\n",
    "                    all_rc[3] = all_rc[3] + 1\n",
    "            i = i + 1\n",
    "        if found_of ==True:\n",
    "           root_cause.append(\"Over Forecasting\")\n",
    "        if found_cp == True:\n",
    "            root_cause.append(\"Case Pack\")\n",
    "    #print(\"after if\")\n",
    "    #if no other root cause discovered-- other\n",
    "    if len(root_cause) == 0:\n",
    "        root_cause.append(\"Other\")\n",
    "        all_rc[4] += 1\n",
    "    final_report.append([d[1],d[0],root_cause])        \n",
    "print(data)\n",
    "#calculate percentage of each root cause entry\n",
    "sum = 0\n",
    "for i in all_rc:\n",
    "    sum = sum + i\n",
    "\n",
    "#print percentages\n",
    "if sum != 0:\n",
    "    print(\"Vendor D&E: \" + str((all_rc[0]/sum)*100) +\"%, New Product Forecast: \" + str((all_rc[1]/sum)*100)+ \"%, Overforecasting:\" + str((all_rc[2]/sum)*100) + \"%, Case Pack:\" + str((all_rc[3]/sum)*100) + \"%, Other:\" + str((all_rc[4]/sum)*100))\n",
    "#print product|location intersection with root cause\n",
    "final_report = pd.DataFrame(final_report, columns=['Product_ID', 'Location_ID','Potential Root Cause'])\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
